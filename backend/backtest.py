"""
Game KPI Projection - Backtest Runner V10.0
============================================
ëª¨ë¸ ì •í™•ë„ ê²€ì¦ì„ ìœ„í•œ ë°±í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    cd backend
    python backtest.py
"""

import json
import numpy as np
import os
import math
from typing import List, Dict

# ============================================================
# MODEL LOGIC (main.pyì—ì„œ ì¶”ì¶œ)
# ============================================================
def generate_retention_curve(d1: float, days: int, decay_power: float = -0.5) -> List[float]:
    """ë¦¬í…ì…˜ ì»¤ë¸Œ ìƒì„± (D1ë¶€í„° ì‹œì‘)"""
    curve = []
    for t in range(1, days + 1):
        ret = d1 * (t ** decay_power)
        curve.append(min(1.0, max(0.0, ret)))
    return curve

def calculate_blended_curve(
    internal: List[float], 
    benchmark: List[float], 
    days: int, 
    quality_mult: float = 1.0
) -> List[float]:
    """ë‚´ë¶€ ë°ì´í„°ì™€ ë²¤ì¹˜ë§ˆí¬ ë¸”ë Œë”©"""
    blended = []
    last_int_val = internal[-1] if internal else 0
    last_bench_val = benchmark[-1] if benchmark else 0
    
    for i in range(days):
        w_int = max(0.1, 0.9 - (0.8 * i / max(1, days - 1)))
        val_int = internal[i] if i < len(internal) else last_int_val
        val_bench = benchmark[i] if i < len(benchmark) else last_bench_val
        final_val = (val_int * w_int) + (val_bench * quality_mult * (1 - w_int))
        blended.append(max(0, final_val))
    
    return blended

# ============================================================
# BACKTEST RUNNER
# ============================================================
def run_backtest():
    """
    ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    - ë‚´ë¶€ ê²Œì„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì •í™•ë„ ê²€ì¦
    - D30ê¹Œì§€ ê´€ì¸¡ â†’ D60 ì˜ˆì¸¡ ì˜¤ì°¨ ì¸¡ì •
    """
    print("\n" + "=" * 60)
    print("ğŸ”¬ Game KPI Projection Model - Backtest Runner V10.0")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    data_path = os.path.join(os.path.dirname(__file__), "..", "data", "raw_game_data.json")
    
    if not os.path.exists(data_path):
        print("âŒ Error: raw_game_data.json not found")
        print(f"   Expected path: {data_path}")
        return
    
    with open(data_path, "r", encoding='utf-8') as f:
        data = json.load(f)
    
    games = data.get('games', {}).get('retention', {})
    
    if not games:
        print("âŒ Error: No retention data found in raw_game_data.json")
        return
    
    print(f"\nğŸ“Š Found {len(games)} games with retention data")
    
    results = []
    detailed_results = []
    
    # 2. ë¸”ë¼ì¸ë“œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    print("\nğŸ“ˆ Running Blind Tests (D30 â†’ D60 Prediction)...")
    print("-" * 60)
    
    for game_name, actual_curve in games.items():
        # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ (ìµœì†Œ 60ì¼ í•„ìš”)
        if len(actual_curve) < 60:
            print(f"  âš ï¸ {game_name}: Skipped (only {len(actual_curve)} days)")
            continue
        
        # Input: D1 ê°’ (ì‹¤ì œ ê´€ì¸¡)
        actual_d1 = actual_curve[0]
        
        # Prediction: Power Law ëª¨ë¸
        predicted_curve = generate_retention_curve(actual_d1, 60, -0.5)
        
        # ì˜¤ì°¨ ê³„ì‚° (D31 ~ D60 êµ¬ê°„)
        errors = []
        for i in range(30, 60):
            actual = actual_curve[i]
            pred = predicted_curve[i]
            if actual > 0:
                err = abs(pred - actual) / actual
                errors.append(err)
        
        if errors:
            mape = np.mean(errors) * 100
            max_err = np.max(errors) * 100
            results.append({"name": game_name, "mape": mape, "max_err": max_err})
            detailed_results.append({
                "name": game_name,
                "d1_actual": actual_d1,
                "d30_actual": actual_curve[29] if len(actual_curve) > 29 else 0,
                "d30_pred": predicted_curve[29],
                "d60_actual": actual_curve[59] if len(actual_curve) > 59 else 0,
                "d60_pred": predicted_curve[59],
                "mape": mape
            })
            print(f"  âœ“ {game_name:<25}: MAPE = {mape:.1f}%")
    
    # 3. ì¢…í•© ë¦¬í¬íŠ¸
    if results:
        print("\n" + "=" * 60)
        print("ğŸ“Š BACKTEST SUMMARY REPORT")
        print("=" * 60)
        
        avg_mape = np.mean([r['mape'] for r in results])
        median_mape = np.median([r['mape'] for r in results])
        max_mape = np.max([r['mape'] for r in results])
        min_mape = np.min([r['mape'] for r in results])
        
        print(f"\nğŸ¯ Overall Performance:")
        print(f"   - Games Tested: {len(results)}")
        print(f"   - Average MAPE: {avg_mape:.2f}%")
        print(f"   - Median MAPE:  {median_mape:.2f}%")
        print(f"   - Best Case:    {min_mape:.2f}%")
        print(f"   - Worst Case:   {max_mape:.2f}%")
        
        # ì‹ ë¢°ë„ íŒì •
        print("\nğŸ“‹ Model Confidence Level:")
        if avg_mape < 15:
            print("   âœ… HIGH CONFIDENCE (ì˜¤ì°¨ìœ¨ 15% ë¯¸ë§Œ)")
            print("   â†’ ì˜ì‚¬ê²°ì • ì°¸ê³  ìë£Œë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            confidence = "HIGH"
        elif avg_mape < 25:
            print("   âš ï¸ MODERATE (ì˜¤ì°¨ìœ¨ 15~25%)")
            print("   â†’ Normal/Worst ì‹œë‚˜ë¦¬ì˜¤ ìœ„ì£¼ë¡œ ê²€í† í•˜ì„¸ìš”.")
            confidence = "MODERATE"
        elif avg_mape < 35:
            print("   âš ï¸ LOW-MODERATE (ì˜¤ì°¨ìœ¨ 25~35%)")
            print("   â†’ Worst ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì‹ ë¢°í•˜ì„¸ìš”.")
            confidence = "LOW-MODERATE"
        else:
            print("   âŒ LOW CONFIDENCE (ì˜¤ì°¨ìœ¨ 35% ì´ˆê³¼)")
            print("   â†’ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¬ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            confidence = "LOW"
        
        # Top 3 Best / Worst
        sorted_results = sorted(results, key=lambda x: x['mape'])
        
        print("\nğŸ† Best Predictions (ê°€ì¥ ì •í™•í•œ ê²Œì„):")
        for r in sorted_results[:3]:
            print(f"   - {r['name']}: {r['mape']:.1f}%")
        
        print("\nâš ï¸ Worst Predictions (ê°€ì¥ ë¶€ì •í™•í•œ ê²Œì„):")
        for r in sorted_results[-3:]:
            print(f"   - {r['name']}: {r['mape']:.1f}%")
        
        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š Detailed Results:")
        print("-" * 80)
        print(f"{'Game':<25} {'D1 Act':>8} {'D30 Act':>8} {'D30 Pred':>9} {'D60 Act':>8} {'D60 Pred':>9} {'MAPE':>8}")
        print("-" * 80)
        for d in detailed_results:
            print(f"{d['name']:<25} {d['d1_actual']:>8.3f} {d['d30_actual']:>8.3f} {d['d30_pred']:>9.3f} "
                  f"{d['d60_actual']:>8.3f} {d['d60_pred']:>9.3f} {d['mape']:>7.1f}%")
        
        # ê²°ë¡ 
        print("\n" + "=" * 60)
        print("ğŸ“ CONCLUSION")
        print("=" * 60)
        print(f"   Model Version: V10.0")
        print(f"   Test Period: D31 ~ D60")
        print(f"   Confidence: {confidence}")
        print(f"   Average Error: {avg_mape:.1f}%")
        
        if confidence in ["HIGH", "MODERATE"]:
            print("\n   âœ… ì´ ëª¨ë¸ì€ ì˜ì‚¬ê²°ì • ì§€ì› ë„êµ¬ë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            print("   ë‹¨, ì¥ê¸° ì˜ˆì¸¡(D90+)ì€ ì¶”ê°€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            print("\n   âš ï¸ ëª¨ë¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤:")
            print("   1. Decay Power íŒŒë¼ë¯¸í„° ì¡°ì • (í˜„ì¬: -0.5)")
            print("   2. ì¥ë¥´/í”Œë«í¼ë³„ ì„¸ë¶„í™”")
            print("   3. ë” ë§ì€ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘")
        
    else:
        print("\nâš ï¸ No games with 60+ days of data found.")
        print("   ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” ìµœì†Œ 60ì¼ ì´ìƒì˜ ë¦¬í…ì…˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    print("\n" + "=" * 60 + "\n")

# ============================================================
# MAIN
# ============================================================
if __name__ == "__main__":
    run_backtest()
